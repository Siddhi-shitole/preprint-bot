{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a947e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting feedparser\n",
      "  Downloading feedparser-6.0.11-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting sgmllib3k (from feedparser)\n",
      "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Downloading feedparser-6.0.11-py3-none-any.whl (81 kB)\n",
      "Building wheels for collected packages: sgmllib3k\n",
      "  Building wheel for sgmllib3k (pyproject.toml): started\n",
      "  Building wheel for sgmllib3k (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6105 sha256=5dd777e36aa50b96fde190847a63f8bcaa783eb99b484c1d1cf2fc65c0a42c44\n",
      "  Stored in directory: c:\\users\\udayan\\appdata\\local\\pip\\cache\\wheels\\3d\\4d\\ef\\37cdccc18d6fd7e0dd7817dcdf9146d4d6789c32a227a28134\n",
      "Successfully built sgmllib3k\n",
      "Installing collected packages: sgmllib3k, feedparser\n",
      "Successfully installed feedparser-6.0.11 sgmllib3k-1.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install feedparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e9db1c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting requests\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests)\n",
      "  Downloading charset_normalizer-3.4.2-cp313-cp313-win_amd64.whl.metadata (36 kB)\n",
      "Collecting idna<4,>=2.5 (from requests)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests)\n",
      "  Using cached urllib3-2.4.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests)\n",
      "  Downloading certifi-2025.4.26-py3-none-any.whl.metadata (2.5 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading certifi-2025.4.26-py3-none-any.whl (159 kB)\n",
      "Downloading charset_normalizer-3.4.2-cp313-cp313-win_amd64.whl (105 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached urllib3-2.4.0-py3-none-any.whl (128 kB)\n",
      "Installing collected packages: urllib3, idna, charset-normalizer, certifi, requests\n",
      "Successfully installed certifi-2025.4.26 charset-normalizer-3.4.2 idna-3.10 requests-2.32.3 urllib3-2.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script normalizer.exe is installed in 'c:\\Users\\Udayan\\AppData\\Local\\Programs\\Python\\Python313\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "036cbf15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp313-cp313-win_amd64.whl.metadata (19 kB)\n",
      "Collecting numpy>=1.26.0 (from pandas)\n",
      "  Downloading numpy-2.2.6-cp313-cp313-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\udayan\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\udayan\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading pandas-2.2.3-cp313-cp313-win_amd64.whl (11.5 MB)\n",
      "   ---------------------------------------- 0.0/11.5 MB ? eta -:--:--\n",
      "   --------------------------- ------------ 7.9/11.5 MB 45.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.5/11.5 MB 44.0 MB/s eta 0:00:00\n",
      "Downloading numpy-2.2.6-cp313-cp313-win_amd64.whl (12.6 MB)\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 12.6/12.6 MB 68.9 MB/s eta 0:00:00\n",
      "Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: pytz, tzdata, numpy, pandas\n",
      "Successfully installed numpy-2.2.6 pandas-2.2.3 pytz-2025.2 tzdata-2025.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The scripts f2py.exe and numpy-config.exe are installed in 'c:\\Users\\Udayan\\AppData\\Local\\Programs\\Python\\Python313\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25edc185",
   "metadata": {},
   "source": [
    "# Fetching recent papers from Arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be70586d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import feedparser\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddb7cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_papers(category=\"physics\", max_results=100, sort_by=\"submittedDate\"):\n",
    "    base_url = \"http://export.arxiv.org/api/query?\"\n",
    "    query = f\"search_query=cat:{category}&start=0&max_results={max_results}&sortBy={sort_by}&sortOrder=descending\"\n",
    "\n",
    "    response = requests.get(base_url + query)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f\"Failed to fetch data: HTTP {response.status_code}\")\n",
    "\n",
    "    feed = feedparser.parse(response.content)\n",
    "    \n",
    "    if not feed.entries:\n",
    "        print(f\"No entries found for category '{category}'. Try a different category or adjust filters.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    papers = []\n",
    "    for entry in feed.entries:\n",
    "        \n",
    "        ## Code to filter out only preprints\n",
    "        # journal_ref = getattr(entry, \"arxiv_journal_ref\", None)\n",
    "        # doi = getattr(entry, \"arxiv_doi\", None)\n",
    "\n",
    "        # # Skip if the paper has been published\n",
    "        # if journal_ref or doi:\n",
    "        #     continue\n",
    "\n",
    "        paper = {\n",
    "            \"title\": entry.title,\n",
    "            \"authors\": \", \".join(author.name for author in entry.authors),\n",
    "            \"summary\": entry.summary,\n",
    "            \"published\": entry.published,\n",
    "            \"updated\": entry.updated,\n",
    "            \"arxiv_url\": entry.link,\n",
    "            \"pdf_url\": next((link.href for link in entry.links if link.type == \"application/pdf\"), None),\n",
    "            \"categories\": \", \".join(tag[\"term\"] for tag in entry.tags) if \"tags\" in entry else \"\",\n",
    "            \"journal_ref\": getattr(entry, \"arxiv_journal_ref\", None),\n",
    "            \"doi\": getattr(entry, \"arxiv_doi\", None)\n",
    "        }\n",
    "        papers.append(paper)\n",
    "\n",
    "    return pd.DataFrame(papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b9d0f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 100 preprints. Files saved as arxiv_preprints_astro-ph_20250519_103836.csv and .json\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    category = \"astro-ph\"\n",
    "    max_results = 100     # Adjust this number as needed\n",
    "\n",
    "    df = fetch_papers(category=category, max_results=max_results)\n",
    "\n",
    "    if not df.empty:\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        # df.to_csv(f\"arxiv_preprints_{category}_{timestamp}.csv\", index=False)\n",
    "        df.to_json(f\"arxiv_preprints_{category}_{timestamp}.json\", orient=\"records\", indent=2)\n",
    "        print(f\"Fetched {len(df)} preprints. Files saved as arxiv_preprints_{category}_{timestamp}.csv and .json\")\n",
    "    else:\n",
    "        print(\"No preprints found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf91e5f2",
   "metadata": {},
   "source": [
    "# Downloading the PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9a774f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0bfd9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded: Bremsstrahlung_emission_from_nuclear_reactions_in_compact_stars\n",
      "Downloaded: Towards_a_warped_inflationary_brane_scanning\n",
      "Error downloading Ultraviolet_Spectra_of_Local_Galaxies_and_their_Link_with_the_High-z\n",
      "__Population: [Errno 22] Invalid argument: 'pdfs\\\\Ultraviolet_Spectra_of_Local_Galaxies_and_their_Link_with_the_High-z\\n__Population.pdf'\n",
      "Downloaded: Correlated_variability_in_the_blazar_3C_454.3\n",
      "Error downloading Biases_and_Uncertainties_in_Physical_Parameter_Estimates_of_Lyman_Break\n",
      "__Galaxies_from_Broad-band_Photometry: [Errno 22] Invalid argument: 'pdfs\\\\Biases_and_Uncertainties_in_Physical_Parameter_Estimates_of_Lyman_Break\\n__Galaxies_from_Broad-band_Photometry.pdf'\n",
      "Error downloading Dynamics_of_a_Spherical_Accretion_Shock_with_Neutrino_Heating_and\n",
      "__Alpha-Particle_Recombination: [Errno 22] Invalid argument: 'pdfs\\\\Dynamics_of_a_Spherical_Accretion_Shock_with_Neutrino_Heating_and\\n__Alpha-Particle_Recombination.pdf'\n",
      "Downloaded: Asymptotically_FRW_black_holes\n",
      "Downloaded: Quantum_Black_Holes_As_Elementary_Particles\n",
      "Error downloading Reaction_of_Accretion_Disks_to_Abrupt_Mass_Loss_During_Binary_Black_Hole\n",
      "__Merger: [Errno 22] Invalid argument: 'pdfs\\\\Reaction_of_Accretion_Disks_to_Abrupt_Mass_Loss_During_Binary_Black_Hole\\n__Merger.pdf'\n",
      "Error downloading A_Gamma-Ray_Burst_Pulsar_for_Cosmic-Ray_Positrons_with_a_Dark\n",
      "__Matter-like_Spectrum: [Errno 22] Invalid argument: 'pdfs\\\\A_Gamma-Ray_Burst_Pulsar_for_Cosmic-Ray_Positrons_with_a_Dark\\n__Matter-like_Spectrum.pdf'\n",
      "Error downloading Catastrophic_Photo-z_Errors_and_the_Dark_Energy_Parameter_Estimates_with\n",
      "__Cosmic_Shear: [Errno 22] Invalid argument: 'pdfs\\\\Catastrophic_Photo-z_Errors_and_the_Dark_Energy_Parameter_Estimates_with\\n__Cosmic_Shear.pdf'\n",
      "Downloaded: Stellar_Ages_from_Stellar_Rotation\n",
      "Downloaded: An_Evolutionary_Considerations_for_V228_from_47_Tuc\n",
      "Error downloading Source_region_of_the_2003_November_18_CME_that_led_to_the_strongest\n",
      "__magnetic_storm_of_cycle_23: [Errno 22] Invalid argument: 'pdfs\\\\Source_region_of_the_2003_November_18_CME_that_led_to_the_strongest\\n__magnetic_storm_of_cycle_23.pdf'\n",
      "Downloaded: Further_progress_on_solar_age_calibration\n",
      "Downloaded: Bulk_viscosity_of_strange_matter_and_r-modes_in_neutron_stars\n",
      "Error downloading Necessity_of_Dark_Matter_in_Modified_Newtonian_Dynamics_within_Galactic\n",
      "__Scales?_-_Testing_the_Covariant_MOND_in_Elliptical_Lenses: [Errno 22] Invalid argument: 'pdfs\\\\Necessity_of_Dark_Matter_in_Modified_Newtonian_Dynamics_within_Galactic\\n__Scales?_-_Testing_the_Covariant_MOND_in_Elliptical_Lenses.pdf'\n",
      "Downloaded: Origin_of_Europa_and_the_Galilean_Satellites\n",
      "Downloaded: High_Accuracy_Near-infrared_Imaging_Polarimetry_with_NICMOS\n",
      "Downloaded: Active_Galactic_Nuclei,_Radio_Jets_and_Acceleration_of_UHECRs\n",
      "Downloaded: Compressed_sensing_imaging_techniques_for_radio_interferometry\n",
      "Downloaded: The_CHilean_Automatic_Supernova_sEarch_(CHASE)\n",
      "Downloaded: Measuring_interstellar_magnetic_fields_by_radio_synchrotron_emission\n",
      "Downloaded: Intermediate_inflation_on_the_brane\n",
      "Downloaded: Friedmann_cosmology_with_bulk_viscosity:_a_concrete_model_for_dark\n",
      "__energy\n",
      "Downloaded: Detecting_Solar_Neutrino_Flare_in_Megaton_and_km^3_detectors\n",
      "Downloaded: Anisotropic_distribution_functions_for_spherical_galaxies\n",
      "Error downloading Consistency_of_Equations_in_the_Second-order_Gauge-invariant\n",
      "__Cosmological_Perturbation_Theory: [Errno 22] Invalid argument: 'pdfs\\\\Consistency_of_Equations_in_the_Second-order_Gauge-invariant\\n__Cosmological_Perturbation_Theory.pdf'\n",
      "Downloaded: Quantum_vacuum_and_accelerated_expansion\n",
      "Downloaded: Near-IR_spectroscopic_ages_of_massive_star_clusters_in_M82\n",
      "Downloaded: Infall_and_rotation_motions_in_the_HH_111_protostellar_system:_A\n",
      "__flattened_envelope_in_transition_to_a_disk?\n",
      "Downloaded: Untwisting_magnetospheres_of_neutron_stars\n",
      "Downloaded: Dynamic_masses_for_the_close_PG1159_binary_SDSSJ212531.92-010745.9\n",
      "Error downloading Long-term_photometric_monitoring_of_the_hybrid_subdwarf_B_pulsator\n",
      "__HS0702+6043: [Errno 22] Invalid argument: 'pdfs\\\\Long-term_photometric_monitoring_of_the_hybrid_subdwarf_B_pulsator\\n__HS0702+6043.pdf'\n",
      "Downloaded: Spectroscopy_of_the_sdB_pulsator_HS2201+2610\n",
      "Downloaded: Multi-wavelength_photometric_variation_of_PG1605+072\n",
      "Error downloading PIERNIK_mhd_code_-_a_multi-fluid,_non-ideal_extension_of_the\n",
      "__relaxing-TVD_scheme_(III): [Errno 22] Invalid argument: 'pdfs\\\\PIERNIK_mhd_code_-_a_multi-fluid,_non-ideal_extension_of_the\\n__relaxing-TVD_scheme_(III).pdf'\n",
      "Downloaded: Dark_Stars:_the_First_Stars_in_the_Universe_may_be_powered_by_Dark\n",
      "__Matter_Heating\n",
      "Downloaded: Orbital_resonances_in_discs_around_braneworld_Kerr_black_holes\n",
      "Downloaded: The_variation_of_the_electromagnetic_coupling_and_quintessence\n",
      "Downloaded: 3D_Spectroscopic_Study_of_the_Line_Emitting_Regions_of_Mrk_493\n",
      "Downloaded: Angular_Energy_Distribution_of_Collapsar-Jets\n",
      "Downloaded: Explosions_inside_Ejecta_and_Most_Luminous_Supernovae\n",
      "Downloaded: Quasi-viscous_accretion_flow_--_I:_Equilibrium_conditions_and_asymptotic\n",
      "__behaviour\n",
      "Error downloading Observations_of_the_pulsation_of_the_Cepheid_l_Car_with_the_Sydney\n",
      "__University_Stellar_Interferometer: [Errno 22] Invalid argument: 'pdfs\\\\Observations_of_the_pulsation_of_the_Cepheid_l_Car_with_the_Sydney\\n__University_Stellar_Interferometer.pdf'\n",
      "Downloaded: Jet_breaks_and_Energetics_of_Swift_GRB_X-ray_Afterglows\n",
      "Error downloading Constraints_on_Dark_Energy_from_the_Observed_Expansion_of_our_Cosmic\n",
      "__Horizon: [Errno 22] Invalid argument: 'pdfs\\\\Constraints_on_Dark_Energy_from_the_Observed_Expansion_of_our_Cosmic\\n__Horizon.pdf'\n",
      "Downloaded: Reversal_of_the_amplitude_difference_of_kHz_QPOs_in_six_atoll_sources\n",
      "Downloaded: The_origin_of_'Great_Walls'\n",
      "Downloaded: Thermal_axion_constraints_in_non-standard_thermal_histories\n",
      "Error downloading Realistic_analytic_model_for_the_prompt_and_high_latitude_emission_in\n",
      "__GRBs: [Errno 22] Invalid argument: 'pdfs\\\\Realistic_analytic_model_for_the_prompt_and_high_latitude_emission_in\\n__GRBs.pdf'\n",
      "Downloaded: Rapid_pulsations_in_sub-THz_solar_bursts\n",
      "Downloaded: Photometric_Properties_of_the_Near-contact_Binary_GW_Geminorum\n",
      "Error downloading Preheating_in_the_Standard_Model_with_the_Higgs-Inflaton_coupled_to\n",
      "__gravity: [Errno 22] Invalid argument: 'pdfs\\\\Preheating_in_the_Standard_Model_with_the_Higgs-Inflaton_coupled_to\\n__gravity.pdf'\n",
      "Downloaded: Adiabatic_expansion_and_magnetic_fields_in_AGN_jets\n",
      "Downloaded: Probing_parsec_scale_jets_in_AGN_with_geodetic_VLBI\n",
      "Downloaded: Search_for_the_magnetic_field_of_the_O7.5_III_star_xi_Persei\n",
      "Downloaded: A_New_Model_For_Vela_Jr._Supernova_Remnant\n",
      "Downloaded: The_magnetic_field_of_the_B3V_star_16_Pegasi\n",
      "Downloaded: Scenarios_for_GCRT_J1745-3009\n",
      "Error downloading Band-power_reconstruction_of_the_primordial_fluctuation_spectrum_by_the\n",
      "__maximum_likelihood_reconstruction_method: [Errno 22] Invalid argument: 'pdfs\\\\Band-power_reconstruction_of_the_primordial_fluctuation_spectrum_by_the\\n__maximum_likelihood_reconstruction_method.pdf'\n",
      "Error downloading Model_of_Reconnection_of_Weakly_Stochastic_Magnetic_Field_and_its\n",
      "__Testing: [Errno 22] Invalid argument: 'pdfs\\\\Model_of_Reconnection_of_Weakly_Stochastic_Magnetic_Field_and_its\\n__Testing.pdf'\n",
      "Downloaded: Grain_alignment_induced_by_radiative_torques:_effects_of_internal\n",
      "__relaxation_of_energy_and_complex_radiation_fields\n",
      "Downloaded: Null_geodesics_and_observational_cosmology\n",
      "Downloaded: On_Dark_Energy_and_Dark_Matter_(Part_I)\n",
      "Downloaded: Near-infrared_bulge-disc_correlations_of_lenticular_galaxies\n",
      "Error downloading Is_the_PAMELA_Positron_Excess_Winos?: [Errno 22] Invalid argument: 'pdfs\\\\Is_the_PAMELA_Positron_Excess_Winos?.pdf'\n",
      "Error downloading Do_non-relativistic_neutrinos_constitute_the_dark_matter?: [Errno 22] Invalid argument: 'pdfs\\\\Do_non-relativistic_neutrinos_constitute_the_dark_matter?.pdf'\n",
      "Downloaded: Explaining_the_Orbits_of_the_Galactic_Center_S-Stars\n",
      "Downloaded: The_ACS_Survey_of_Galactic_Globular_Clusters._VII._Relative_Ages\n",
      "Downloaded: Nonlinear_Density_Fluctuation_Field_Theory_for_Large_Scale_Structure\n",
      "Downloaded: New_BVRI_photometry_results_on_KBOs_from_the_ESO_VLT\n",
      "Downloaded: High_Inclination_Planets_in_Multistellar_Systems\n",
      "Error downloading Nodeless_differentially_rotational_Alfvén_oscillations_of_crustal\n",
      "__solid-state_plasma_in_quaking_neutron_star: [Errno 22] Invalid argument: 'pdfs\\\\Nodeless_differentially_rotational_Alfvén_oscillations_of_crustal\\n__solid-state_plasma_in_quaking_neutron_star.pdf'\n",
      "Error downloading Orbital_Phase_Spectroscopy_of_four_High_Mass_X-ray_Binary_Pulsars_to\n",
      "__Study_the_Stellar_Wind_of_the_Companion: [Errno 22] Invalid argument: 'pdfs\\\\Orbital_Phase_Spectroscopy_of_four_High_Mass_X-ray_Binary_Pulsars_to\\n__Study_the_Stellar_Wind_of_the_Companion.pdf'\n",
      "Downloaded: Relaxing_the_Cosmological_Constraints_on_Unparticle_Dark_Component\n",
      "Downloaded: Holography,_UV_IR_Relation,_Causal_Entropy_Bound_and_Dark_Energy\n",
      "Downloaded: Probing_Dark_Energy_at_Galactic_and_Cluster_Scales\n",
      "Downloaded: Strange_Quark_stars:_Observations_&_Speculations\n",
      "Error downloading Effects_of_Minor_Mergers_on_Coalescence_of_a_Supermassive_Black_Hole\n",
      "__Binary: [Errno 22] Invalid argument: 'pdfs\\\\Effects_of_Minor_Mergers_on_Coalescence_of_a_Supermassive_Black_Hole\\n__Binary.pdf'\n",
      "Error downloading Intensity_Distribution_and_Luminosity_Function_of_the_Swift_Gamma-Ray\n",
      "__Bursts: [Errno 22] Invalid argument: 'pdfs\\\\Intensity_Distribution_and_Luminosity_Function_of_the_Swift_Gamma-Ray\\n__Bursts.pdf'\n",
      "Downloaded: Small-scale_solar_magnetic_fields\n",
      "Downloaded: Dissecting_cosmic-ray_electron-positron_data_with_Occam's_Razor:_the\n",
      "__role_of_known_Pulsars\n",
      "Downloaded: Black_Holes_Admitting_Strong_Resonant_Phenomena\n",
      "Downloaded: Dynamical_and_thermal_evolution_of_the_quark-nova_ejecta\n",
      "Downloaded: Shape_and_kinematics_of_elliptical_galaxies:_evolution_due_to_merging_at\n",
      "__z_<_1.5\n",
      "Downloaded: The_very_short_supersoft_X-ray_state_of_the_classical_nova_M31N_2007-11a\n",
      "Downloaded: Recoil_velocity_at_2PN_order_for_spinning_black_hole_binaries\n",
      "Error downloading A_model_for_the_Z-track_phenomenon_in_GX_5-1_and_observational_evidence\n",
      "__for_the_physical_origins_of_the_kHz_QPO: [Errno 22] Invalid argument: 'pdfs\\\\A_model_for_the_Z-track_phenomenon_in_GX_5-1_and_observational_evidence\\n__for_the_physical_origins_of_the_kHz_QPO.pdf'\n",
      "Downloaded: Abell_851_and_the_Role_of_Starbursts_in_Cluster_Galaxy_Evolution\n",
      "Downloaded: The_Magnetic_Sensitivity_of_the_Second_Solar_Spectrum\n",
      "Error downloading Testing_the_predictions_of_the_cold_dark_matter_model_for_the_sizes,\n",
      "__colours,_morphologies_and_luminosities_of_galaxies_with_the_SDSS: [Errno 22] Invalid argument: 'pdfs\\\\Testing_the_predictions_of_the_cold_dark_matter_model_for_the_sizes,\\n__colours,_morphologies_and_luminosities_of_galaxies_with_the_SDSS.pdf'\n",
      "Error downloading Neutron_specific_heat_in_the_crust_of_neutron_stars_from_the_nuclear\n",
      "__band_theory: [Errno 22] Invalid argument: 'pdfs\\\\Neutron_specific_heat_in_the_crust_of_neutron_stars_from_the_nuclear\\n__band_theory.pdf'\n",
      "Downloaded: Synchronization_mechanism_of_sharp_edges_in_rings_of_Saturn\n",
      "Downloaded: Disentangling_age_and_metallicity_in_distant_unresolved_stellar_systems\n",
      "Error downloading Gravitational_wave_background_as_a_probe_of_the_primordial_black_hole\n",
      "__abundance: [Errno 22] Invalid argument: 'pdfs\\\\Gravitational_wave_background_as_a_probe_of_the_primordial_black_hole\\n__abundance.pdf'\n",
      "Downloaded: The_Role_of_Massive_Agb_Stars_in_the_Early_Solar_System_Composition\n",
      "Downloaded: Two_more_disk_galaxies_with_global_gas_counterrotation\n",
      "Downloaded: Equation_of_state_of_classical_Coulomb_plasma_mixtures\n",
      "Downloaded: The_Role_of_the_Random_Magnetic_Fields_in_the_ISM:_HVCs_Numerical\n",
      "__Simulations\n"
     ]
    }
   ],
   "source": [
    "def get_arxiv_pdf_url(arxiv_url):\n",
    "    \"\"\"Extract the paper ID from the arxiv_url and construct the direct PDF link.\"\"\"\n",
    "    try:\n",
    "        paper_id = arxiv_url.split('/')[-1]\n",
    "        return f\"https://arxiv.org/pdf/{paper_id}.pdf\"\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def download_pdfs(json_file, output_dir=\"pdfs\"):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    with open(json_file, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    for idx, entry in enumerate(data):\n",
    "        arxiv_url = entry.get(\"arxiv_url\")\n",
    "        pdf_url = get_arxiv_pdf_url(arxiv_url)\n",
    "        title = entry.get(\"title\", f\"paper_{idx}\").replace(\" \", \"_\").replace(\"/\", \"_\")\n",
    "\n",
    "        if pdf_url:\n",
    "            try: \n",
    "                response = requests.get(pdf_url)\n",
    "                if response.headers.get('Content-Type') == 'application/pdf':\n",
    "                    pdf_path = os.path.join(output_dir, f\"{title}.pdf\")\n",
    "                    with open(pdf_path, 'wb') as pdf_file:\n",
    "                        pdf_file.write(response.content)\n",
    "                    print(f\"Downloaded: {title}\")\n",
    "                else:\n",
    "                    print(f\"Failed to download (Not a PDF): {title}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error downloading {title}: {e}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    download_pdfs(\"arxiv_preprints_astro-ph_20250519_103836.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8d96c4",
   "metadata": {},
   "source": [
    "# Extracting the Introduction and Conclusion sections from the pdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "95c06bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyMuPDF\n",
      "  Downloading pymupdf-1.25.5-cp39-abi3-win_amd64.whl.metadata (3.4 kB)\n",
      "Downloading pymupdf-1.25.5-cp39-abi3-win_amd64.whl (16.6 MB)\n",
      "   ---------------------------------------- 0.0/16.6 MB ? eta -:--:--\n",
      "   -------------- ------------------------- 6.0/16.6 MB 41.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 16.0/16.6 MB 46.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 16.6/16.6 MB 41.9 MB/s eta 0:00:00\n",
      "Installing collected packages: PyMuPDF\n",
      "Successfully installed PyMuPDF-1.25.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script pymupdf.exe is installed in 'c:\\Users\\Udayan\\AppData\\Local\\Programs\\Python\\Python313\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install PyMuPDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a90b8901",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fitz\n",
    "import re\n",
    "\n",
    "def extract_sections(text):\n",
    "    text = re.sub(r'\\n+', '\\n', text)\n",
    "\n",
    "    intro_pattern = re.compile(r'(?:^|\\n)(\\d{0,2}\\.?\\s*)?(Introduction)\\s*\\n', re.IGNORECASE)\n",
    "    section_heading_pattern = re.compile(r'(?:^|\\n)(\\d{0,2}\\.?\\s*)?[A-Z][^\\n]{0,50}\\s*\\n')\n",
    "    concl_pattern = re.compile(r'(?:^|\\n)(\\d{0,2}\\.?\\s*)?(Conclusion|Conclusions|Discussion)\\s*\\n', re.IGNORECASE)\n",
    "    end_content_pattern = re.compile(r'(?:^|\\n)(\\d{0,2}\\.?\\s*)?(References|Acknowledgments?|Appendix|Bibliography)\\s*\\n', re.IGNORECASE)\n",
    "\n",
    "    # Extract Introduction\n",
    "    intro_match = intro_pattern.search(text)\n",
    "    intro_text = \"\"\n",
    "    if intro_match:\n",
    "        intro_start = intro_match.end()\n",
    "        next_section_match = section_heading_pattern.search(text, intro_start)\n",
    "        if next_section_match:\n",
    "            intro_text = text[intro_start:next_section_match.start()]\n",
    "        else:\n",
    "            intro_text = text[intro_start:]\n",
    "\n",
    "    # Extract Conclusion\n",
    "    concl_match = concl_pattern.search(text)\n",
    "    concl_text = \"\"\n",
    "    if concl_match:\n",
    "        concl_start = concl_match.end()\n",
    "        end_match = end_content_pattern.search(text, concl_start)\n",
    "        if end_match:\n",
    "            concl_text = text[concl_start:end_match.start()]\n",
    "        else:\n",
    "            concl_text = text[concl_start:]\n",
    "\n",
    "    return intro_text.strip(), concl_text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "39dd3480",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text(pdf_dir=\"pdfs\", output_dir=\"texts\"):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    for filename in os.listdir(pdf_dir):\n",
    "        if filename.endswith(\".pdf\"):\n",
    "            pdf_path = os.path.join(pdf_dir, filename)\n",
    "            doc = fitz.open(pdf_path)\n",
    "            full_text = \"\"\n",
    "            for page in doc:\n",
    "                full_text += page.get_text()\n",
    "            \n",
    "            intro_text, concl_text = extract_sections(full_text)\n",
    "\n",
    "            extracted_text = f\"Introduction:\\n{intro_text}\\n\\nConclusion:\\n{concl_text}\"\n",
    "\n",
    "            text_path = os.path.join(output_dir, f\"{os.path.splitext(filename)[0]}.txt\")\n",
    "            with open(text_path, 'w', encoding='utf-8') as f:\n",
    "                f.write(extracted_text)\n",
    "            \n",
    "            print(f\"Processed: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ba9e6e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 3D_Spectroscopic_Study_of_the_Line_Emitting_Regions_of_Mrk_493.pdf\n",
      "Processed: Abell_851_and_the_Role_of_Starbursts_in_Cluster_Galaxy_Evolution.pdf\n",
      "Processed: Active_Galactic_Nuclei,_Radio_Jets_and_Acceleration_of_UHECRs.pdf\n",
      "Processed: Adiabatic_expansion_and_magnetic_fields_in_AGN_jets.pdf\n",
      "Processed: Angular_Energy_Distribution_of_Collapsar-Jets.pdf\n",
      "Processed: Anisotropic_distribution_functions_for_spherical_galaxies.pdf\n",
      "Processed: An_Evolutionary_Considerations_for_V228_from_47_Tuc.pdf\n",
      "Processed: Asymptotically_FRW_black_holes.pdf\n",
      "Processed: A_New_Model_For_Vela_Jr._Supernova_Remnant.pdf\n",
      "Processed: Black_Holes_Admitting_Strong_Resonant_Phenomena.pdf\n",
      "Processed: Bremsstrahlung_emission_from_nuclear_reactions_in_compact_stars.pdf\n",
      "Processed: Bulk_viscosity_of_strange_matter_and_r-modes_in_neutron_stars.pdf\n",
      "Processed: Compressed_sensing_imaging_techniques_for_radio_interferometry.pdf\n",
      "Processed: Correlated_variability_in_the_blazar_3C_454.3.pdf\n",
      "Processed: Detecting_Solar_Neutrino_Flare_in_Megaton_and_km^3_detectors.pdf\n",
      "Processed: Disentangling_age_and_metallicity_in_distant_unresolved_stellar_systems.pdf\n",
      "Processed: Dynamical_and_thermal_evolution_of_the_quark-nova_ejecta.pdf\n",
      "Processed: Dynamic_masses_for_the_close_PG1159_binary_SDSSJ212531.92-010745.9.pdf\n",
      "Processed: Equation_of_state_of_classical_Coulomb_plasma_mixtures.pdf\n",
      "Processed: Explaining_the_Orbits_of_the_Galactic_Center_S-Stars.pdf\n",
      "Processed: Explosions_inside_Ejecta_and_Most_Luminous_Supernovae.pdf\n",
      "Processed: Further_progress_on_solar_age_calibration.pdf\n",
      "Processed: High_Accuracy_Near-infrared_Imaging_Polarimetry_with_NICMOS.pdf\n",
      "Processed: High_Inclination_Planets_in_Multistellar_Systems.pdf\n",
      "Processed: Holography,_UV_IR_Relation,_Causal_Entropy_Bound_and_Dark_Energy.pdf\n",
      "Processed: Intermediate_inflation_on_the_brane.pdf\n",
      "Processed: Jet_breaks_and_Energetics_of_Swift_GRB_X-ray_Afterglows.pdf\n",
      "Processed: Measuring_interstellar_magnetic_fields_by_radio_synchrotron_emission.pdf\n",
      "Processed: Multi-wavelength_photometric_variation_of_PG1605+072.pdf\n",
      "Processed: Near-infrared_bulge-disc_correlations_of_lenticular_galaxies.pdf\n",
      "Processed: Near-IR_spectroscopic_ages_of_massive_star_clusters_in_M82.pdf\n",
      "Processed: New_BVRI_photometry_results_on_KBOs_from_the_ESO_VLT.pdf\n",
      "Processed: Nonlinear_Density_Fluctuation_Field_Theory_for_Large_Scale_Structure.pdf\n",
      "Processed: Null_geodesics_and_observational_cosmology.pdf\n",
      "Processed: On_Dark_Energy_and_Dark_Matter_(Part_I).pdf\n",
      "Processed: Orbital_resonances_in_discs_around_braneworld_Kerr_black_holes.pdf\n",
      "Processed: Origin_of_Europa_and_the_Galilean_Satellites.pdf\n",
      "Processed: Photometric_Properties_of_the_Near-contact_Binary_GW_Geminorum.pdf\n",
      "Processed: Probing_Dark_Energy_at_Galactic_and_Cluster_Scales.pdf\n",
      "Processed: Probing_parsec_scale_jets_in_AGN_with_geodetic_VLBI.pdf\n",
      "Processed: Quantum_Black_Holes_As_Elementary_Particles.pdf\n",
      "Processed: Quantum_vacuum_and_accelerated_expansion.pdf\n",
      "Processed: Rapid_pulsations_in_sub-THz_solar_bursts.pdf\n",
      "Processed: Recoil_velocity_at_2PN_order_for_spinning_black_hole_binaries.pdf\n",
      "Processed: Relaxing_the_Cosmological_Constraints_on_Unparticle_Dark_Component.pdf\n",
      "Processed: Reversal_of_the_amplitude_difference_of_kHz_QPOs_in_six_atoll_sources.pdf\n",
      "Processed: Scenarios_for_GCRT_J1745-3009.pdf\n",
      "Processed: Search_for_the_magnetic_field_of_the_O7.5_III_star_xi_Persei.pdf\n",
      "Processed: Small-scale_solar_magnetic_fields.pdf\n",
      "Processed: Spectroscopy_of_the_sdB_pulsator_HS2201+2610.pdf\n",
      "Processed: Stellar_Ages_from_Stellar_Rotation.pdf\n",
      "Processed: Synchronization_mechanism_of_sharp_edges_in_rings_of_Saturn.pdf\n",
      "Processed: Thermal_axion_constraints_in_non-standard_thermal_histories.pdf\n",
      "Processed: The_ACS_Survey_of_Galactic_Globular_Clusters._VII._Relative_Ages.pdf\n",
      "Processed: The_CHilean_Automatic_Supernova_sEarch_(CHASE).pdf\n",
      "Processed: The_magnetic_field_of_the_B3V_star_16_Pegasi.pdf\n",
      "Processed: The_Magnetic_Sensitivity_of_the_Second_Solar_Spectrum.pdf\n",
      "Processed: The_origin_of_'Great_Walls'.pdf\n",
      "Processed: The_Role_of_Massive_Agb_Stars_in_the_Early_Solar_System_Composition.pdf\n",
      "Processed: The_variation_of_the_electromagnetic_coupling_and_quintessence.pdf\n",
      "Processed: The_very_short_supersoft_X-ray_state_of_the_classical_nova_M31N_2007-11a.pdf\n",
      "Processed: Towards_a_warped_inflationary_brane_scanning.pdf\n",
      "Processed: Two_more_disk_galaxies_with_global_gas_counterrotation.pdf\n",
      "Processed: Untwisting_magnetospheres_of_neutron_stars.pdf\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    extract_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2161fab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning dataset saved to finetune_data.jsonl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def prepare_finetuning_data(json_file, text_dir=\"texts\", output_file=\"finetune_data.jsonl\"):\n",
    "    with open(json_file, 'r', encoding='utf-8') as f:\n",
    "        metadata = json.load(f)\n",
    "\n",
    "    with open(output_file, 'w', encoding='utf-8') as fout:\n",
    "        for idx, entry in enumerate(metadata):\n",
    "            title = entry.get(\"title\", \"No Title\")\n",
    "            summary = entry.get(\"summary\", \"\").strip()\n",
    "            cleaned_title = title.replace(\" \", \"_\").replace(\"/\", \"_\")\n",
    "            text_path = os.path.join(text_dir, f\"{cleaned_title}.txt\")\n",
    "\n",
    "            if not os.path.exists(text_path):\n",
    "                continue\n",
    "\n",
    "            with open(text_path, 'r', encoding='utf-8') as f:\n",
    "                extracted_text = f.read().strip()\n",
    "\n",
    "            if not extracted_text:\n",
    "                continue\n",
    "\n",
    "            prompt = f\"Summarize the Introduction and Conclusion of the following paper titled '{title}':\\n\\n{extracted_text}\"\n",
    "\n",
    "            response = summary if summary else \"To be filled.\"\n",
    "\n",
    "            sample = {\n",
    "                \"prompt\": prompt,\n",
    "                \"response\": response\n",
    "            }\n",
    "\n",
    "            fout.write(json.dumps(sample) + \"\\n\")\n",
    "\n",
    "    print(f\"Fine-tuning dataset saved to {output_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    prepare_finetuning_data(\"arxiv_preprints_astro-ph_20250519_103836.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf1c647",
   "metadata": {},
   "source": [
    "# Fine tuning on smaller models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7815779d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Using cached transformers-4.51.3-py3-none-any.whl.metadata (38 kB)\n",
      "Collecting datasets\n",
      "  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting accelerate\n",
      "  Downloading accelerate-1.7.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.45.5-py3-none-win_amd64.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\udayan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (3.18.0)\n",
      "Collecting huggingface-hub<1.0,>=0.30.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.31.4-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\udayan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\udayan\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (25.0)\n",
      "Collecting pyyaml>=5.1 (from transformers)\n",
      "  Downloading PyYAML-6.0.2-cp313-cp313-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.11.6-cp313-cp313-win_amd64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\udayan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Using cached tokenizers-0.21.1-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting tqdm>=4.27 (from transformers)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting pyarrow>=15.0.0 (from datasets)\n",
      "  Downloading pyarrow-20.0.0-cp313-cp313-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\udayan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets) (2.2.3)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp313-cp313-win_amd64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Using cached multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: psutil in c:\\users\\udayan\\appdata\\roaming\\python\\python313\\site-packages (from accelerate) (7.0.0)\n",
      "Collecting torch>=2.0.0 (from accelerate)\n",
      "  Downloading torch-2.7.0-cp313-cp313-win_amd64.whl.metadata (29 kB)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading aiohttp-3.11.18-cp313-cp313-win_amd64.whl.metadata (8.0 kB)\n",
      "Collecting typing-extensions>=3.7.4.3 (from huggingface-hub<1.0,>=0.30.0->transformers)\n",
      "  Using cached typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\udayan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\udayan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\udayan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\udayan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->transformers) (2025.4.26)\n",
      "Collecting sympy>=1.13.3 (from torch>=2.0.0->accelerate)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: networkx in c:\\users\\udayan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
      "Collecting jinja2 (from torch>=2.0.0->accelerate)\n",
      "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\udayan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch>=2.0.0->accelerate) (65.5.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\udayan\\appdata\\roaming\\python\\python313\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\udayan\\appdata\\roaming\\python\\python313\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\udayan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\udayan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Using cached aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Using cached attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading frozenlist-1.6.0-cp313-cp313-win_amd64.whl.metadata (16 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading multidict-6.4.4-cp313-cp313-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading propcache-0.3.1-cp313-cp313-win_amd64.whl.metadata (11 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading yarl-1.20.0-cp313-cp313-win_amd64.whl.metadata (74 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\udayan\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch>=2.0.0->accelerate)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch>=2.0.0->accelerate)\n",
      "  Downloading MarkupSafe-3.0.2-cp313-cp313-win_amd64.whl.metadata (4.1 kB)\n",
      "Using cached transformers-4.51.3-py3-none-any.whl (10.4 MB)\n",
      "Downloading datasets-3.6.0-py3-none-any.whl (491 kB)\n",
      "Downloading accelerate-1.7.0-py3-none-any.whl (362 kB)\n",
      "Downloading bitsandbytes-0.45.5-py3-none-win_amd64.whl (75.4 MB)\n",
      "   ---------------------------------------- 0.0/75.4 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 6.6/75.4 MB 32.0 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 14.4/75.4 MB 34.7 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 22.5/75.4 MB 36.4 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 35.4/75.4 MB 43.1 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 49.3/75.4 MB 48.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 61.3/75.4 MB 49.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 72.6/75.4 MB 50.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  75.2/75.4 MB 50.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 75.4/75.4 MB 45.5 MB/s eta 0:00:00\n",
      "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Downloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "Downloading huggingface_hub-0.31.4-py3-none-any.whl (489 kB)\n",
      "Using cached multiprocess-0.70.16-py312-none-any.whl (146 kB)\n",
      "Downloading pyarrow-20.0.0-cp313-cp313-win_amd64.whl (25.7 MB)\n",
      "   ---------------------------------------- 0.0/25.7 MB ? eta -:--:--\n",
      "   ------------------------- -------------- 16.5/25.7 MB 80.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 25.7/25.7 MB 65.8 MB/s eta 0:00:00\n",
      "Downloading PyYAML-6.0.2-cp313-cp313-win_amd64.whl (156 kB)\n",
      "Downloading regex-2024.11.6-cp313-cp313-win_amd64.whl (273 kB)\n",
      "Downloading safetensors-0.5.3-cp38-abi3-win_amd64.whl (308 kB)\n",
      "Using cached tokenizers-0.21.1-cp39-abi3-win_amd64.whl (2.4 MB)\n",
      "Downloading torch-2.7.0-cp313-cp313-win_amd64.whl (212.5 MB)\n",
      "   ---------------------------------------- 0.0/212.5 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 16.3/212.5 MB 80.9 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 31.7/212.5 MB 78.6 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 47.2/212.5 MB 76.1 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 62.7/212.5 MB 76.1 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 79.2/212.5 MB 77.3 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 95.2/212.5 MB 76.6 MB/s eta 0:00:02\n",
      "   ------------------- ------------------- 108.8/212.5 MB 75.2 MB/s eta 0:00:02\n",
      "   ----------------------- --------------- 126.9/212.5 MB 76.6 MB/s eta 0:00:02\n",
      "   -------------------------- ------------ 144.2/212.5 MB 77.3 MB/s eta 0:00:01\n",
      "   ----------------------------- --------- 161.0/212.5 MB 77.8 MB/s eta 0:00:01\n",
      "   ------------------------------- ------- 173.5/212.5 MB 76.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 188.0/212.5 MB 76.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 204.7/212.5 MB 76.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.3/212.5 MB 76.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.3/212.5 MB 76.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.3/212.5 MB 76.7 MB/s eta 0:00:01\n",
      "   --------------------------------------- 212.5/212.5 MB 60.6 MB/s eta 0:00:00\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading xxhash-3.5.0-cp313-cp313-win_amd64.whl (30 kB)\n",
      "Downloading aiohttp-3.11.18-cp313-cp313-win_amd64.whl (437 kB)\n",
      "Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "   ---------------------------------------- 0.0/6.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 6.3/6.3 MB 56.5 MB/s eta 0:00:00\n",
      "Using cached typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
      "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Downloading frozenlist-1.6.0-cp313-cp313-win_amd64.whl (119 kB)\n",
      "Downloading MarkupSafe-3.0.2-cp313-cp313-win_amd64.whl (15 kB)\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   --------------------------------------- 536.2/536.2 kB 18.7 MB/s eta 0:00:00\n",
      "Downloading multidict-6.4.4-cp313-cp313-win_amd64.whl (38 kB)\n",
      "Downloading propcache-0.3.1-cp313-cp313-win_amd64.whl (44 kB)\n",
      "Downloading yarl-1.20.0-cp313-cp313-win_amd64.whl (92 kB)\n",
      "Installing collected packages: mpmath, xxhash, typing-extensions, tqdm, sympy, safetensors, regex, pyyaml, pyarrow, propcache, multidict, MarkupSafe, fsspec, frozenlist, dill, attrs, aiohappyeyeballs, yarl, multiprocess, jinja2, huggingface-hub, aiosignal, torch, tokenizers, aiohttp, transformers, bitsandbytes, accelerate, datasets\n",
      "Successfully installed MarkupSafe-3.0.2 accelerate-1.7.0 aiohappyeyeballs-2.6.1 aiohttp-3.11.18 aiosignal-1.3.2 attrs-25.3.0 bitsandbytes-0.45.5 datasets-3.6.0 dill-0.3.8 frozenlist-1.6.0 fsspec-2025.3.0 huggingface-hub-0.31.4 jinja2-3.1.6 mpmath-1.3.0 multidict-6.4.4 multiprocess-0.70.16 propcache-0.3.1 pyarrow-20.0.0 pyyaml-6.0.2 regex-2024.11.6 safetensors-0.5.3 sympy-1.14.0 tokenizers-0.21.1 torch-2.7.0 tqdm-4.67.1 transformers-4.51.3 typing-extensions-4.13.2 xxhash-3.5.0 yarl-1.20.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script tqdm.exe is installed in 'c:\\Users\\Udayan\\AppData\\Local\\Programs\\Python\\Python313\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script isympy.exe is installed in 'c:\\Users\\Udayan\\AppData\\Local\\Programs\\Python\\Python313\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script huggingface-cli.exe is installed in 'c:\\Users\\Udayan\\AppData\\Local\\Programs\\Python\\Python313\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts torchfrtrace.exe and torchrun.exe are installed in 'c:\\Users\\Udayan\\AppData\\Local\\Programs\\Python\\Python313\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script transformers-cli.exe is installed in 'c:\\Users\\Udayan\\AppData\\Local\\Programs\\Python\\Python313\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts accelerate-config.exe, accelerate-estimate-memory.exe, accelerate-launch.exe, accelerate-merge-weights.exe and accelerate.exe are installed in 'c:\\Users\\Udayan\\AppData\\Local\\Programs\\Python\\Python313\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script datasets-cli.exe is installed in 'c:\\Users\\Udayan\\AppData\\Local\\Programs\\Python\\Python313\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install transformers datasets accelerate bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34ccf196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting peft\n",
      "  Downloading peft-0.15.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\udayan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from peft) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\udayan\\appdata\\roaming\\python\\python313\\site-packages (from peft) (25.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\udayan\\appdata\\roaming\\python\\python313\\site-packages (from peft) (7.0.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\udayan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from peft) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.13.0 in c:\\users\\udayan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from peft) (2.7.0)\n",
      "Requirement already satisfied: transformers in c:\\users\\udayan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from peft) (4.51.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\udayan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from peft) (4.67.1)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in c:\\users\\udayan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from peft) (1.7.0)\n",
      "Requirement already satisfied: safetensors in c:\\users\\udayan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from peft) (0.5.3)\n",
      "Requirement already satisfied: huggingface_hub>=0.25.0 in c:\\users\\udayan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from peft) (0.31.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\udayan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface_hub>=0.25.0->peft) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\udayan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface_hub>=0.25.0->peft) (2025.3.0)\n",
      "Requirement already satisfied: requests in c:\\users\\udayan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface_hub>=0.25.0->peft) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\udayan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface_hub>=0.25.0->peft) (4.13.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\udayan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch>=1.13.0->peft) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\udayan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch>=1.13.0->peft) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\udayan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch>=1.13.0->peft) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\udayan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch>=1.13.0->peft) (65.5.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\udayan\\appdata\\roaming\\python\\python313\\site-packages (from tqdm->peft) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\udayan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers->peft) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\udayan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers->peft) (0.21.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\udayan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sympy>=1.13.3->torch>=1.13.0->peft) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\udayan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\udayan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->huggingface_hub>=0.25.0->peft) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\udayan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->huggingface_hub>=0.25.0->peft) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\udayan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->huggingface_hub>=0.25.0->peft) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\udayan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->huggingface_hub>=0.25.0->peft) (2025.4.26)\n",
      "Downloading peft-0.15.2-py3-none-any.whl (411 kB)\n",
      "Installing collected packages: peft\n",
      "Successfully installed peft-0.15.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4b77f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer, DataCollatorForLanguageModeling\n",
    "from datasets import load_dataset\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "197c96bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Udayan\\AppData\\Local\\Temp\\ipykernel_9956\\3398598816.py:31: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "c:\\Users\\Udayan\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='96' max='96' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [96/96 32:17, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3.805600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>3.710300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>3.620700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>3.368800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>3.268300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>3.436500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>3.317400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>3.131900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>3.206600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=96, training_loss=3.4160989125569663, metrics={'train_runtime': 1964.9505, 'train_samples_per_second': 0.098, 'train_steps_per_second': 0.049, 'total_flos': 100336140288000.0, 'train_loss': 3.4160989125569663, 'epoch': 3.0})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"json\", data_files=\"finetune_data.jsonl\")\n",
    "model_name = \"gpt2\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "def tokenize(batch):\n",
    "    prompt = batch[\"prompt\"]\n",
    "    response = batch[\"response\"]\n",
    "    full_text = prompt + \"\\n\\n#### Summary: \\n\" + response\n",
    "    return tokenizer(full_text, truncation=True, padding=\"max_length\", max_length=1024)\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize, batched=False)\n",
    "tokenized_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"])\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./gpt2-finetuned-summary\",\n",
    "    per_device_train_batch_size=2,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=5e-5,\n",
    "    weight_decay=0.01, \n",
    "    logging_steps=10,\n",
    "    save_steps=500,\n",
    "    save_total_limit=2,\n",
    "    fp16=torch.cuda.is_available()\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model, \n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    tokenizer= tokenizer,\n",
    "    data_collator= data_collator\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b17e97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./gpt2-finetuned-summary\\\\tokenizer_config.json',\n",
       " './gpt2-finetuned-summary\\\\special_tokens_map.json',\n",
       " './gpt2-finetuned-summary\\\\vocab.json',\n",
       " './gpt2-finetuned-summary\\\\merges.txt',\n",
       " './gpt2-finetuned-summary\\\\added_tokens.json',\n",
       " './gpt2-finetuned-summary\\\\tokenizer.json')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model and tokenizer after training  \n",
    "trainer.save_model(\"./gpt2-finetuned-summary\")\n",
    "tokenizer.save_pretrained(\"./gpt2-finetuned-summary\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd025893",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarize the Introduction and Conclusion of the following paper:\n",
      "\n",
      "Introduction: ...\n",
      "\n",
      "Conclusion: ...\n",
      "We present an introduction and conclusion of the next part of the following paper titled 'The Role of Subatomic Radiation in Photonic Field Properties'\n",
      "Introduction:\n",
      "We discuss the relationship between the atomic energy and subatomic radiation. In particular the role of atomic radiation in electromagnetic fields for all the known properties such as luminosity, polarization angle, motion, chromaticity, polarisation, and so on, namely\n",
      "in particular their photonic properties. This paper presents these properties in a simple,\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summarizer = pipeline(\"text-generation\", model=\"./gpt2-finetuned-summary\", tokenizer=tokenizer)\n",
    "prompt = \"Summarize the Introduction and Conclusion of the following paper:\\n\\nIntroduction: ...\\n\\nConclusion: ...\"\n",
    "print(summarizer(prompt, max_new_tokens=100)[0][\"generated_text\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
